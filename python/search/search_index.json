{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PyVq","text":"<p>PyVq provides Python bindings for the Vq vector quantization library.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>High-performance Rust implementation with Python bindings</li> <li>NumPy array support for input and output</li> <li>All quantization algorithms: BinaryQuantizer, ScalarQuantizer, ProductQuantizer, TSVQ</li> <li>SIMD-accelerated distance computations</li> <li>Simple, Pythonic API</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import numpy as np\nimport pyvq\n\n# Binary Quantization\nbq = pyvq.BinaryQuantizer(threshold=0.0, low=0, high=1)\nvector = np.array([-0.5, 0.0, 0.5, 1.0], dtype=np.float32)\ncodes = bq.quantize(vector)\nprint(f\"Quantized: {codes}\")  # [0, 1, 1, 1]\n\n# Scalar Quantization\nsq = pyvq.ScalarQuantizer(min=-1.0, max=1.0, levels=256)\nquantized = sq.quantize(vector)\nreconstructed = sq.dequantize(quantized)\nprint(f\"Reconstructed: {reconstructed}\")\n\n# Distance Computation\ndist = pyvq.Distance.euclidean()\na = np.array([1.0, 2.0, 3.0], dtype=np.float32)\nb = np.array([4.0, 5.0, 6.0], dtype=np.float32)\nresult = dist.compute(a, b)\nprint(f\"Euclidean distance: {result}\")\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pyvq\n</code></pre> <p>Requires Python 3.10 or later.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - Installation and first steps</li> <li>Examples - Complete code examples</li> <li>API Reference - Full API documentation</li> </ul>"},{"location":"#rust-library","title":"Rust Library","text":"<p>For the Rust library documentation, see docs.rs/vq or the main documentation.</p> <p>Early Development</p> <p>PyVq is in early development. Please report bugs on GitHub Issues.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for PyVq.</p>"},{"location":"api-reference/#distance","title":"Distance","text":"<pre><code>class Distance:\n    \"\"\"Compute vector distances with SIMD acceleration.\"\"\"\n\n    @staticmethod\n    def euclidean() -&gt; Distance\n\n    @staticmethod\n    def squared_euclidean() -&gt; Distance\n\n    @staticmethod\n    def manhattan() -&gt; Distance\n\n    @staticmethod\n    def cosine() -&gt; Distance\n\n    def compute(self, a: np.ndarray, b: np.ndarray) -&gt; float\n        \"\"\"Compute distance between two float32 arrays.\"\"\"\n</code></pre> <p>Example: <pre><code>dist = pyvq.Distance.euclidean()\nresult = dist.compute(np.array([1.0, 2.0], dtype=np.float32),\n                      np.array([3.0, 4.0], dtype=np.float32))\n</code></pre></p>"},{"location":"api-reference/#binaryquantizer","title":"BinaryQuantizer","text":"<pre><code>class BinaryQuantizer:\n    \"\"\"Maps values to 0 or 1 based on a threshold.\"\"\"\n\n    def __init__(self, threshold: float, low: int = 0, high: int = 1)\n\n    def quantize(self, values: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: float32, Output: uint8\"\"\"\n\n    def dequantize(self, codes: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: uint8, Output: float32\"\"\"\n\n    # Properties\n    threshold: float\n    low: int\n    high: int\n</code></pre> <p>Example: <pre><code>bq = pyvq.BinaryQuantizer(threshold=0.0)\ncodes = bq.quantize(np.array([-0.5, 0.5], dtype=np.float32))\n# Returns: [0, 1]\n</code></pre></p>"},{"location":"api-reference/#scalarquantizer","title":"ScalarQuantizer","text":"<pre><code>class ScalarQuantizer:\n    \"\"\"Uniformly quantizes values to discrete levels.\"\"\"\n\n    def __init__(self, min: float, max: float, levels: int = 256)\n\n    def quantize(self, values: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: float32, Output: uint8\"\"\"\n\n    def dequantize(self, codes: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: uint8, Output: float32\"\"\"\n\n    # Properties\n    min: float\n    max: float\n    levels: int\n    step: float\n</code></pre> <p>Example: <pre><code>sq = pyvq.ScalarQuantizer(min=-1.0, max=1.0, levels=256)\ncodes = sq.quantize(np.array([0.0, 0.5], dtype=np.float32))\nreconstructed = sq.dequantize(codes)\n</code></pre></p>"},{"location":"api-reference/#productquantizer","title":"ProductQuantizer","text":"<pre><code>class ProductQuantizer:\n    \"\"\"Divides vectors into subspaces and quantizes each separately.\"\"\"\n\n    def __init__(\n        self,\n        training_data: np.ndarray,  # 2D float32 array\n        num_subspaces: int,\n        num_centroids: int,\n        max_iters: int = 10,\n        distance: Distance = None,\n        seed: int = 42\n    )\n\n    def quantize(self, vector: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: float32, Output: float16\"\"\"\n\n    def dequantize(self, codes: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: float16, Output: float32\"\"\"\n\n    # Properties\n    num_subspaces: int\n    sub_dim: int\n    dim: int\n</code></pre> <p>Example: <pre><code>training = np.random.randn(100, 16).astype(np.float32)\npq = pyvq.ProductQuantizer(\n    training_data=training,\n    num_subspaces=4,\n    num_centroids=8,\n    distance=pyvq.Distance.euclidean()\n)\ncodes = pq.quantize(training[0])\n</code></pre></p>"},{"location":"api-reference/#tsvq","title":"TSVQ","text":"<pre><code>class TSVQ:\n    \"\"\"Tree-structured vector quantizer using hierarchical clustering.\"\"\"\n\n    def __init__(\n        self,\n        training_data: np.ndarray,  # 2D float32 array\n        max_depth: int,\n        distance: Distance = None\n    )\n\n    def quantize(self, vector: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: float32, Output: float16\"\"\"\n\n    def dequantize(self, codes: np.ndarray) -&gt; np.ndarray\n        \"\"\"Input: float16, Output: float32\"\"\"\n\n    # Properties\n    dim: int\n</code></pre> <p>Example: <pre><code>training = np.random.randn(100, 32).astype(np.float32)\ntsvq = pyvq.TSVQ(\n    training_data=training,\n    max_depth=5,\n    distance=pyvq.Distance.squared_euclidean()\n)\ncodes = tsvq.quantize(training[0])\n</code></pre></p>"},{"location":"api-reference/#utility-functions","title":"Utility Functions","text":"<pre><code>def get_simd_backend() -&gt; str:\n    \"\"\"Returns the active SIMD backend (e.g., 'AVX2 (Auto)').\"\"\"\n</code></pre>"},{"location":"api-reference/#type-summary","title":"Type Summary","text":"Quantizer Input quantize() Output dequantize() Output BinaryQuantizer float32 uint8 float32 ScalarQuantizer float32 uint8 float32 ProductQuantizer float32 float16 float32 TSVQ float32 float16 float32"},{"location":"examples/","title":"Examples","text":"<p>Complete code examples demonstrating PyVq usage patterns.</p>"},{"location":"examples/#embedding-compression-with-scalar-quantization","title":"Embedding Compression with Scalar Quantization","text":"<pre><code>import numpy as np\nimport pyvq\n\n# Simulate embeddings (normally from a model)\nembeddings = np.random.randn(1000, 768).astype(np.float32)\n\n# Normalize to [-1, 1] range\nembeddings = embeddings / np.abs(embeddings).max()\n\n# Create scalar quantizer\nsq = pyvq.ScalarQuantizer(min=-1.0, max=1.0, levels=256)\n\n# Compress all embeddings\ncompressed = [sq.quantize(e) for e in embeddings]\n\n# Calculate compression ratio\noriginal_bytes = embeddings.nbytes\ncompressed_bytes = sum(c.nbytes for c in compressed)\nprint(f\"Original: {original_bytes:,} bytes\")\nprint(f\"Compressed: {compressed_bytes:,} bytes\")\nprint(f\"Ratio: {original_bytes / compressed_bytes:.1f}x\")\n\n# Verify reconstruction quality\nreconstructed = np.array([sq.dequantize(c) for c in compressed])\nmse = np.mean((embeddings - reconstructed) ** 2)\nprint(f\"MSE: {mse:.6f}\")\n</code></pre>"},{"location":"examples/#product-quantization-for-similarity-search","title":"Product Quantization for Similarity Search","text":"<pre><code>import numpy as np\nimport pyvq\n\n# Create a database of vectors\ndatabase = np.random.randn(10000, 128).astype(np.float32)\n\n# Train product quantizer\npq = pyvq.ProductQuantizer(\n    training_data=database[:1000],  # Use subset for training\n    num_subspaces=16,    # 16 subspaces\n    num_centroids=256,   # 256 centroids each\n    max_iters=10,\n    distance=pyvq.Distance.squared_euclidean(),\n    seed=42\n)\n\n# Quantize entire database\nquantized_db = [pq.quantize(v) for v in database]\n\n# Query - find approximate nearest neighbors\nquery = np.random.randn(128).astype(np.float32)\nquery_quantized = pq.quantize(query)\n\n# Compare distances using reconstructed vectors\ndist = pyvq.Distance.squared_euclidean()\ndistances = []\nfor i, qv in enumerate(quantized_db):\n    recon = pq.dequantize(qv)\n    d = dist.compute(query, recon)\n    distances.append((i, d))\n\n# Get top-5 nearest\nnearest = sorted(distances, key=lambda x: x[1])[:5]\nprint(\"Top 5 nearest indices:\", [n[0] for n in nearest])\n</code></pre>"},{"location":"examples/#binary-hashing-for-fast-similarity","title":"Binary Hashing for Fast Similarity","text":"<pre><code>import numpy as np\nimport pyvq\n\ndef hamming_distance(a: np.ndarray, b: np.ndarray) -&gt; int:\n    \"\"\"Count differing bits between two binary vectors.\"\"\"\n    return np.sum(a != b)\n\n# Create binary quantizer\nbq = pyvq.BinaryQuantizer(threshold=0.0, low=0, high=1)\n\n# Hash some vectors\nvectors = [\n    np.array([0.5, -0.3, 0.1, -0.8, 0.2], dtype=np.float32),\n    np.array([0.4, -0.2, 0.0, -0.7, 0.3], dtype=np.float32),  # Similar\n    np.array([-0.6, 0.4, -0.2, 0.9, -0.1], dtype=np.float32), # Different\n]\n\nhashes = [bq.quantize(v) for v in vectors]\n\n# Compare using Hamming distance (fast!)\nprint(f\"Hash 0 vs 1: {hamming_distance(hashes[0], hashes[1])}\")  # Low\nprint(f\"Hash 0 vs 2: {hamming_distance(hashes[0], hashes[2])}\")  # High\n</code></pre>"},{"location":"examples/#comparing-distance-metrics","title":"Comparing Distance Metrics","text":"<pre><code>import numpy as np\nimport pyvq\n\n# Create test vectors\nnp.random.seed(42)\na = np.random.randn(100).astype(np.float32)\nb = np.random.randn(100).astype(np.float32)\n\n# All distance metrics\nmetrics = [\n    (\"Euclidean\", pyvq.Distance.euclidean()),\n    (\"Squared Euclidean\", pyvq.Distance.squared_euclidean()),\n    (\"Manhattan\", pyvq.Distance.manhattan()),\n    (\"Cosine Distance\", pyvq.Distance.cosine()),\n]\n\nprint(\"Distance between random 100-d vectors:\")\nfor name, dist in metrics:\n    result = dist.compute(a, b)\n    print(f\"  {name:20s}: {result:.4f}\")\n\n# SIMD backend info\nprint(f\"\\nSIMD Backend: {pyvq.get_simd_backend()}\")\n</code></pre>"},{"location":"examples/#error-analysis","title":"Error Analysis","text":"<pre><code>import numpy as np\nimport pyvq\n\n# Test reconstruction errors for different quantizers\nvector = np.random.randn(64).astype(np.float32)\n\n# Binary Quantization\nbq = pyvq.BinaryQuantizer(0.0, 0, 1)\nbq_q = bq.quantize(vector)\nbq_r = bq.dequantize(bq_q)\nbq_mse = np.mean((vector - bq_r) ** 2)\n\n# Scalar Quantization\nsq = pyvq.ScalarQuantizer(min=-3.0, max=3.0, levels=256)\nsq_q = sq.quantize(vector)\nsq_r = sq.dequantize(sq_q)\nsq_mse = np.mean((vector - sq_r) ** 2)\n\nprint(f\"Binary Quantizer MSE: {bq_mse:.4f}\")\nprint(f\"Scalar Quantizer MSE: {sq_mse:.6f}\")\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide covers installation and basic usage of PyVq.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install pyvq\n</code></pre> <p>Requirements</p> <p>Python 3.10 or later</p>"},{"location":"getting-started/#binary-quantization","title":"Binary Quantization","text":"<p>Binary quantization maps values to 0 or 1 based on a threshold. It provides at least 75% storage reduction.</p> <pre><code>import numpy as np\nimport pyvq\n\n# Create a binary quantizer\n# Values &gt;= threshold map to high, values &lt; threshold map to low\nbq = pyvq.BinaryQuantizer(threshold=0.0, low=0, high=1)\n\n# Quantize a vector\nvector = np.array([-1.0, -0.5, 0.0, 0.5, 1.0], dtype=np.float32)\ncodes = bq.quantize(vector)\nprint(f\"Input:  {vector}\")\nprint(f\"Output: {codes}\")\n# Output: [0, 0, 1, 1, 1]\n</code></pre>"},{"location":"getting-started/#scalar-quantization","title":"Scalar Quantization","text":"<p>Scalar quantization maps a continuous range to discrete levels.</p> <pre><code>import numpy as np\nimport pyvq\n\n# Create a scalar quantizer\n# Maps values from [-1, 1] to 256 discrete levels\nsq = pyvq.ScalarQuantizer(min=-1.0, max=1.0, levels=256)\n\n# Quantize and dequantize\nvector = np.array([0.1, -0.3, 0.7, -0.9], dtype=np.float32)\nquantized = sq.quantize(vector)\nreconstructed = sq.dequantize(quantized)\n\nprint(f\"Original:      {vector}\")\nprint(f\"Reconstructed: {reconstructed}\")\n</code></pre>"},{"location":"getting-started/#product-quantization","title":"Product Quantization","text":"<p>Product quantization requires training on a dataset. It splits vectors into subspaces and learns codebooks.</p> <pre><code>import numpy as np\nimport pyvq\n\n# Generate training data: 100 vectors of dimension 16\ntraining = np.random.randn(100, 16).astype(np.float32)\n\n# Train a product quantizer\npq = pyvq.ProductQuantizer(\n    training_data=training,\n    num_subspaces=4,   # 4 subspaces (16/4 = 4 dims each)\n    num_centroids=8,   # 8 centroids per subspace\n    max_iters=10,\n    distance=pyvq.Distance.euclidean(),\n    seed=42\n)\n\n# Quantize a vector\nvector = training[0]\nquantized = pq.quantize(vector)\nreconstructed = pq.dequantize(quantized)\n\nprint(f\"Original dimension: {len(vector)}\")\nprint(f\"Quantized dimension: {len(quantized)}\")\n</code></pre>"},{"location":"getting-started/#tree-structured-vq","title":"Tree-Structured VQ","text":"<p>TSVQ builds a binary tree of centroids for hierarchical quantization.</p> <pre><code>import numpy as np\nimport pyvq\n\n# Generate training data\ntraining = np.random.randn(100, 32).astype(np.float32)\n\n# Create TSVQ with max depth 5\ntsvq = pyvq.TSVQ(\n    training_data=training,\n    max_depth=5,\n    distance=pyvq.Distance.squared_euclidean()\n)\n\n# Quantize\nvector = training[0]\nquantized = tsvq.quantize(vector)\nreconstructed = tsvq.dequantize(quantized)\n</code></pre>"},{"location":"getting-started/#distance-computation","title":"Distance Computation","text":"<p>Compute distances between vectors using various metrics:</p> <pre><code>import numpy as np\nimport pyvq\n\na = np.array([1.0, 2.0, 3.0], dtype=np.float32)\nb = np.array([4.0, 5.0, 6.0], dtype=np.float32)\n\n# Different distance metrics\neuclidean = pyvq.Distance.euclidean()\nmanhattan = pyvq.Distance.manhattan()\ncosine = pyvq.Distance.cosine()\nsq_euclidean = pyvq.Distance.squared_euclidean()\n\nprint(f\"Euclidean: {euclidean.compute(a, b)}\")\nprint(f\"Manhattan: {manhattan.compute(a, b)}\")\nprint(f\"Cosine: {cosine.compute(a, b)}\")\nprint(f\"Squared Euclidean: {sq_euclidean.compute(a, b)}\")\n</code></pre>"}]}