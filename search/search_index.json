{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Vq","text":"<p>Vq (vector quantizer) is a vector quantization library for Rust \ud83e\udd80. It provides efficient implementations of popular quantization algorithms for compressing high-dimensional vectors.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Simple and generic API via the <code>Quantizer</code> trait</li> <li>More than 50% reduction in storage size of input vectors</li> <li>SIMD acceleration support (AVX/AVX2/AVX512/NEON/SVE) via the <code>simd</code> feature</li> <li>Multi-threaded training via the <code>parallel</code> feature</li> <li>Multiple distance metrics: Euclidean, Manhattan, and cosine</li> </ul>"},{"location":"#supported-algorithms","title":"Supported Algorithms","text":"Algorithm Training Complexity Quantization Complexity Minimum Storage Reduction Binary (BQ) \\(O(1)\\) \\(O(nd)\\) 75% Scalar (SQ) \\(O(1)\\) \\(O(nd)\\) 75% Product (PQ) \\(O(nkd)\\) \\(O(nd)\\) 50% Tree-Structured (TSVQ) \\(O(n \\log k)\\) \\(O(d \\log k)\\) 50% <p>Where \\(n\\) is number of vectors, \\(d\\) is the number of dimensions of a vector, and \\(k\\) is the number of centroids used in clustering (for PQ and TSVQ).</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>use vq::{BinaryQuantizer, Quantizer};\n\nfn main() -&gt; vq::VqResult&lt;()&gt; {\n    // Create a binary quantizer with threshold 0.0\n    let bq = BinaryQuantizer::new(0.0, 0, 1)?;\n\n    // Quantize a vector\n    let quantized = bq.quantize(&amp;[-1.0, 0.5, 1.0])?;\n    assert_eq!(quantized, vec![0, 1, 1]);\n\n    Ok(())\n}\n</code></pre>"},{"location":"#python-bindings","title":"Python Bindings","text":"<p>Python \ud83d\udc0d bindings are available via PyVq:</p> <pre><code>pip install pyvq\n</code></pre> <p>See the PyVq documentation for Python-specific guides.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started - Installation and first steps</li> <li>Examples - Complete code examples</li> <li>API Reference - API overview</li> <li>docs.rs/vq - Full Rust API documentation</li> <li>GitHub Repository</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>This page provides an overview of Vq's public API. For detailed documentation, see docs.rs/vq.</p>"},{"location":"api-reference/#core-trait","title":"Core Trait","text":""},{"location":"api-reference/#quantizer","title":"<code>Quantizer</code>","text":"<p>All quantization algorithms implement this trait:</p> <pre><code>pub trait Quantizer {\n    type QuantizedOutput;\n\n    fn quantize(&amp;self, vector: &amp;[f32]) -&gt; VqResult&lt;Self::QuantizedOutput&gt;;\n    fn dequantize(&amp;self, quantized: &amp;Self::QuantizedOutput) -&gt; VqResult&lt;Vec&lt;f32&gt;&gt;;\n}\n</code></pre>"},{"location":"api-reference/#quantizers","title":"Quantizers","text":""},{"location":"api-reference/#binaryquantizer","title":"<code>BinaryQuantizer</code>","text":"<p>Maps values above/below a threshold to two discrete levels.</p> <pre><code>// Constructor\nBinaryQuantizer::new(threshold: f32, low: u8, high: u8) -&gt; VqResult&lt;Self&gt;\n\n// Getters\nfn threshold(&amp;self) -&gt; f32\nfn low(&amp;self) -&gt; u8\nfn high(&amp;self) -&gt; u8\n\n// Output type: Vec&lt;u8&gt;\n</code></pre>"},{"location":"api-reference/#scalarquantizer","title":"<code>ScalarQuantizer</code>","text":"<p>Uniformly quantizes values in a range to discrete levels (2-256).</p> <pre><code>// Constructor\nScalarQuantizer::new(min: f32, max: f32, levels: usize) -&gt; VqResult&lt;Self&gt;\n\n// Getters\nfn min(&amp;self) -&gt; f32\nfn max(&amp;self) -&gt; f32\nfn levels(&amp;self) -&gt; usize\nfn step(&amp;self) -&gt; f32\n\n// Output type: Vec&lt;u8&gt;\n</code></pre>"},{"location":"api-reference/#productquantizer","title":"<code>ProductQuantizer</code>","text":"<p>Divides vectors into subspaces and quantizes each using learned codebooks.</p> <pre><code>// Constructor (requires training)\nProductQuantizer::new(\n    training_data: &amp;[&amp;[f32]],\n    m: usize,           // number of subspaces\n    k: usize,           // centroids per subspace\n    max_iters: usize,\n    distance: Distance,\n    seed: u64,\n) -&gt; VqResult&lt;Self&gt;\n\n// Getters\nfn num_subspaces(&amp;self) -&gt; usize\nfn sub_dim(&amp;self) -&gt; usize\nfn dim(&amp;self) -&gt; usize\nfn distance_metric(&amp;self) -&gt; &amp;'static str  // \"euclidean\", \"cosine\", etc.\n\n// Output type: Vec&lt;f16&gt;\n</code></pre>"},{"location":"api-reference/#tsvq","title":"<code>TSVQ</code>","text":"<p>Tree-structured vector quantizer using hierarchical clustering.</p> <pre><code>// Constructor (requires training)\nTSVQ::new(\n    training_data: &amp;[&amp;[f32]],\n    max_depth: usize,\n    distance: Distance,\n) -&gt; VqResult&lt;Self&gt;\n\n// Getters\nfn dim(&amp;self) -&gt; usize\nfn distance_metric(&amp;self) -&gt; &amp;'static str  // \"euclidean\", \"cosine\", etc.\n\n// Output type: Vec&lt;f16&gt;\n</code></pre>"},{"location":"api-reference/#distance-metrics","title":"Distance Metrics","text":""},{"location":"api-reference/#distance","title":"<code>Distance</code>","text":"<p>Enum for computing vector distances:</p> <pre><code>pub enum Distance {\n    SquaredEuclidean,  // L2\u00b2\n    Euclidean,         // L2\n    Manhattan,         // L1\n    CosineDistance,    // 1 - cosine_similarity\n}\n\n// Usage\nDistance::Euclidean.compute(a: &amp;[f32], b: &amp;[f32]) -&gt; VqResult&lt;f32&gt;\n\n// Get metric name\nDistance::Euclidean.name() -&gt; &amp;'static str  // \"euclidean\"\n</code></pre>"},{"location":"api-reference/#vector-operations-advanced","title":"Vector Operations (Advanced)","text":"<p>The <code>Vector&lt;T&gt;</code> type provides fallible arithmetic operations:</p> <pre><code>use vq::core::vector::Vector;\n\n// Fallible operations (return Result)\nvec_a.try_add(&amp;vec_b) -&gt; VqResult&lt;Vector&lt;T&gt;&gt;\nvec_a.try_sub(&amp;vec_b) -&gt; VqResult&lt;Vector&lt;T&gt;&gt;\nvec_a.try_div(scalar) -&gt; VqResult&lt;Vector&lt;T&gt;&gt;\n\n// Trait-based operations (panic on error)\n&amp;vec_a + &amp;vec_b  // panics if dimensions mismatch\n&amp;vec_a - &amp;vec_b\n&amp;vec_a * scalar\n&amp;vec_a / scalar\n\n// Other methods\nvec_a.dot(&amp;vec_b) -&gt; T     // panics if dimensions mismatch\nvec_a.norm() -&gt; T\nvec_a.distance2(&amp;vec_b) -&gt; T\n</code></pre> <p>Note: Use <code>try_*</code> methods for safe error handling, or the trait operators for internal code where dimensions are guaranteed to match.</p>"},{"location":"api-reference/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/#vqerror","title":"<code>VqError</code>","text":"<p>All operations return <code>VqResult&lt;T&gt;</code>, which is <code>Result&lt;T, VqError&gt;</code>:</p> <pre><code>pub enum VqError {\n    /// Vectors have mismatched dimensions\n    DimensionMismatch { expected: usize, found: usize },\n\n    /// Input data is empty\n    EmptyInput,\n\n    /// A configuration parameter is invalid\n    InvalidParameter { parameter: &amp;'static str, reason: String },\n\n    /// Input data contains invalid values (NaN, Infinity, etc.)\n    InvalidData(String),\n\n    /// FFI operation failed\n    FfiError(String),\n}\n</code></pre>"},{"location":"api-reference/#feature-flags","title":"Feature Flags","text":"Feature Description <code>parallel</code> Multi-threaded training for PQ and TSVQ <code>simd</code> SIMD acceleration (AVX/AVX2/AVX512/NEON/SVE) <pre><code>cargo add vq --features parallel,simd\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Complete code examples demonstrating Vq usage patterns.</p>"},{"location":"examples/#binary-quantization-with-hamming-distance","title":"Binary Quantization with Hamming Distance","text":"<pre><code>use vq::{BinaryQuantizer, Quantizer, VqResult};\n\n/// Count the number of differing bits between two binary vectors\nfn hamming_distance(a: &amp;[u8], b: &amp;[u8]) -&gt; usize {\n    a.iter().zip(b.iter()).filter(|(x, y)| x != y).count()\n}\n\nfn main() -&gt; VqResult&lt;()&gt; {\n    let bq = BinaryQuantizer::new(0.0, 0, 1)?;\n\n    // Sample embeddings\n    let embeddings = vec![\n        vec![0.5, -0.3, 0.1, -0.8, 0.2],\n        vec![0.4, -0.2, 0.0, -0.7, 0.3],  // Similar to first\n        vec![-0.6, 0.4, -0.2, 0.9, -0.1], // Different\n    ];\n\n    // Quantize all embeddings\n    let codes: Vec&lt;_&gt; = embeddings.iter()\n        .map(|e| bq.quantize(e))\n        .collect::&lt;VqResult&lt;_&gt;&gt;()?;\n\n    // Compare using Hamming distance\n    println!(\"Hamming(0, 1) = {}\", hamming_distance(&amp;codes[0], &amp;codes[1]));\n    println!(\"Hamming(0, 2) = {}\", hamming_distance(&amp;codes[0], &amp;codes[2]));\n\n    Ok(())\n}\n</code></pre>"},{"location":"examples/#scalar-quantization-with-error-analysis","title":"Scalar Quantization with Error Analysis","text":"<pre><code>use vq::{ScalarQuantizer, Quantizer, VqResult};\n\nfn main() -&gt; VqResult&lt;()&gt; {\n    // Test different quantization levels\n    let levels_to_test = [4, 16, 64, 256];\n    let test_vector: Vec&lt;f32&gt; = (0..100)\n        .map(|i| (i as f32 / 50.0) - 1.0)  // Values in [-1, 1]\n        .collect();\n\n    for levels in levels_to_test {\n        let sq = ScalarQuantizer::new(-1.0, 1.0, levels)?;\n\n        let quantized = sq.quantize(&amp;test_vector)?;\n        let reconstructed = sq.dequantize(&amp;quantized)?;\n\n        let mse: f32 = test_vector.iter()\n            .zip(reconstructed.iter())\n            .map(|(a, b)| (a - b).powi(2))\n            .sum::&lt;f32&gt;() / test_vector.len() as f32;\n\n        let max_error: f32 = test_vector.iter()\n            .zip(reconstructed.iter())\n            .map(|(a, b)| (a - b).abs())\n            .fold(0.0, f32::max);\n\n        println!(\n            \"Levels: {:3} | MSE: {:.6} | Max Error: {:.4}\",\n            levels, mse, max_error\n        );\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"examples/#product-quantization-for-embedding-compression","title":"Product Quantization for Embedding Compression","text":"<pre><code>use vq::{ProductQuantizer, Distance, Quantizer, VqResult};\n\nfn main() -&gt; VqResult&lt;()&gt; {\n    // Simulate 1000 embeddings of dimension 128\n    let embeddings: Vec&lt;Vec&lt;f32&gt;&gt; = (0..1000)\n        .map(|i| {\n            (0..128)\n                .map(|j| ((i * 7 + j * 13) % 1000) as f32 / 500.0 - 1.0)\n                .collect()\n        })\n        .collect();\n    let refs: Vec&lt;&amp;[f32]&gt; = embeddings.iter().map(|v| v.as_slice()).collect();\n\n    // Train PQ: 16 subspaces (128/16 = 8 dims each), 256 centroids\n    println!(\"Training PQ...\");\n    let pq = ProductQuantizer::new(&amp;refs, 16, 256, 15, Distance::SquaredEuclidean, 42)?;\n\n    println!(\"PQ Configuration:\");\n    println!(\"  Dimension: {}\", pq.dim());\n    println!(\"  Subspaces: {}\", pq.num_subspaces());\n    println!(\"  Sub-dimension: {}\", pq.sub_dim());\n\n    // Quantize and measure error\n    let mut total_mse = 0.0;\n    for emb in &amp;embeddings[..100] {\n        let quantized = pq.quantize(emb)?;\n        let reconstructed = pq.dequantize(&amp;quantized)?;\n\n        let mse: f32 = emb.iter()\n            .zip(reconstructed.iter())\n            .map(|(a, b)| (a - b).powi(2))\n            .sum::&lt;f32&gt;() / emb.len() as f32;\n        total_mse += mse;\n    }\n\n    println!(\"Average MSE: {:.6}\", total_mse / 100.0);\n\n    // Storage comparison\n    let original_bytes = 128 * 4;  // 128 floats * 4 bytes\n    let quantized_bytes = 128 * 2; // 128 f16 values * 2 bytes\n    println!(\n        \"Compression: {} bytes -&gt; {} bytes ({:.0}% reduction)\",\n        original_bytes,\n        quantized_bytes,\n        (1.0 - quantized_bytes as f64 / original_bytes as f64) * 100.0\n    );\n\n    Ok(())\n}\n</code></pre>"},{"location":"examples/#distance-computation-comparison","title":"Distance Computation Comparison","text":"<pre><code>use vq::{Distance, VqResult};\n\nfn main() -&gt; VqResult&lt;()&gt; {\n    // Create test vectors\n    let a: Vec&lt;f32&gt; = (0..100).map(|i| i as f32 / 100.0).collect();\n    let b: Vec&lt;f32&gt; = (0..100).map(|i| (i as f32 / 100.0) + 0.1).collect();\n\n    // Compare all distance metrics\n    let metrics = [\n        (\"Squared Euclidean\", Distance::SquaredEuclidean),\n        (\"Euclidean\", Distance::Euclidean),\n        (\"Manhattan\", Distance::Manhattan),\n        (\"Cosine Distance\", Distance::CosineDistance),\n    ];\n\n    for (name, metric) in metrics {\n        let dist = metric.compute(&amp;a, &amp;b)?;\n        println!(\"{:20} = {:.6}\", name, dist);\n    }\n\n    // Check SIMD backend (if enabled)\n    #[cfg(feature = \"simd\")]\n    {\n        println!(\"\\nSIMD Backend: {}\", vq::get_simd_backend());\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"examples/#chaining-quantizers","title":"Chaining Quantizers","text":"<pre><code>use vq::{BinaryQuantizer, ScalarQuantizer, Quantizer, VqResult};\n\nfn main() -&gt; VqResult&lt;()&gt; {\n    let test_vector = vec![0.1, -0.5, 0.8, -0.2, 0.6];\n\n    // Chain quantizers: first SQ, then BQ on reconstructed\n    let sq = ScalarQuantizer::new(-1.0, 1.0, 256)?;\n    let bq = BinaryQuantizer::new(0.5, 0, 1)?;\n\n    // Step 1: Scalar quantization\n    let sq_quantized = sq.quantize(&amp;test_vector)?;\n    let sq_reconstructed = sq.dequantize(&amp;sq_quantized)?;\n\n    // Step 2: Binary quantization on SQ output\n    let bq_quantized = bq.quantize(&amp;sq_reconstructed)?;\n\n    println!(\"Original: {:?}\", test_vector);\n    println!(\"After SQ: {:?}\", sq_reconstructed);\n    println!(\"After BQ: {:?}\", bq_quantized);\n\n    Ok(())\n}\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide covers installation and basic usage of Vq.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>Add Vq to your project:</p> <pre><code>cargo add vq --features parallel,simd\n</code></pre> <p>Requirements</p> <ul> <li>Rust 1.85 or later</li> <li>For <code>simd</code> feature, a C compiler (like GCC or Clang) that supports C11 is needed</li> </ul>"},{"location":"getting-started/#binary-quantization","title":"Binary Quantization","text":"<p>Binary quantization maps values to 0 or 1 based on a threshold. It provides at least 75% storage reduction.</p> <pre><code>use vq::{BinaryQuantizer, Quantizer};\n\nfn main() -&gt; vq::VqResult&lt;()&gt; {\n    // Values &gt;= 0.0 map to 1, values &lt; 0.0 map to 0\n    let bq = BinaryQuantizer::new(0.0, 0, 1)?;\n\n    let vector = vec![-0.5, 0.0, 0.5, 1.0];\n    let quantized = bq.quantize(&amp;vector)?;\n\n    println!(\"Quantized: {:?}\", quantized);\n    // Output: [0, 1, 1, 1]\n\n    Ok(())\n}\n</code></pre>"},{"location":"getting-started/#scalar-quantization","title":"Scalar Quantization","text":"<p>Scalar quantization maps a continuous range to discrete levels. It also provides at least 75% storage reduction.</p> <pre><code>use vq::{ScalarQuantizer, Quantizer};\n\nfn main() -&gt; vq::VqResult&lt;()&gt; {\n    // Map values from [-1.0, 1.0] to 256 levels\n    let sq = ScalarQuantizer::new(-1.0, 1.0, 256)?;\n\n    let vector = vec![-1.0, 0.0, 0.5, 1.0];\n    let quantized = sq.quantize(&amp;vector)?;\n\n    // Reconstruct the vector\n    let reconstructed = sq.dequantize(&amp;quantized)?;\n\n    println!(\"Original:      {:?}\", vector);\n    println!(\"Reconstructed: {:?}\", reconstructed);\n\n    Ok(())\n}\n</code></pre>"},{"location":"getting-started/#product-quantization","title":"Product Quantization","text":"<p>Product quantization requires training on a dataset. It splits vectors into subspaces and learns codebooks.</p> <pre><code>use vq::{ProductQuantizer, Distance, Quantizer};\n\nfn main() -&gt; vq::VqResult&lt;()&gt; {\n    // Generate training data: 100 vectors of dimension 8\n    let training: Vec&lt;Vec&lt;f32&gt;&gt; = (0..100)\n        .map(|i| (0..8).map(|j| ((i + j) % 50) as f32).collect())\n        .collect();\n    let refs: Vec&lt;&amp;[f32]&gt; = training.iter().map(|v| v.as_slice()).collect();\n\n    // Train PQ with 2 subspaces, 4 centroids each\n    let pq = ProductQuantizer::new(\n        &amp;refs,\n        2,    // m: number of subspaces\n        4,    // k: centroids per subspace\n        10,   // max iterations\n        Distance::Euclidean,\n        42,   // random seed\n    )?;\n\n    // Quantize and reconstruct\n    let quantized = pq.quantize(&amp;training[0])?;\n    let reconstructed = pq.dequantize(&amp;quantized)?;\n\n    println!(\"Dimension: {}\", pq.dim());\n    println!(\"Subspaces: {}\", pq.num_subspaces());\n\n    Ok(())\n}\n</code></pre>"},{"location":"getting-started/#distance-computation","title":"Distance Computation","text":"<p>Compute distances between vectors using various metrics:</p> <pre><code>use vq::Distance;\n\nfn main() -&gt; vq::VqResult&lt;()&gt; {\n    let a = vec![1.0, 2.0, 3.0];\n    let b = vec![4.0, 5.0, 6.0];\n\n    let euclidean = Distance::Euclidean.compute(&amp;a, &amp;b)?;\n    let manhattan = Distance::Manhattan.compute(&amp;a, &amp;b)?;\n    let cosine = Distance::CosineDistance.compute(&amp;a, &amp;b)?;\n\n    println!(\"Euclidean: {}\", euclidean);\n    println!(\"Manhattan: {}\", manhattan);\n    println!(\"Cosine distance: {}\", cosine);\n\n    Ok(())\n}\n</code></pre>"}]}